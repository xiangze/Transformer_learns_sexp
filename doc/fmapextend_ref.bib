@article{kobayashi2024analyzing,
title={Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps},
author={Goro Kobayashi and Tatsuki Kuribayashi and Sho Yokoi and Kentaro Inui},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=mYWsyTuiRp}
}

@article{PhysRevLett.94.058102,
  title = {Magic Number $7\ifmmode\pm\else\textpm\fi{}2$ in Networks of Threshold Dynamics},
  author = {Ishihara, Shuji and Kaneko, Kunihiko},
  journal = {Phys. Rev. Lett.},
  volume = {94},
  issue = {5},
  pages = {058102},
  numpages = {4},
  year = {2005},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.94.058102},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.94.058102}
}
@article{Inoue_2022,
   title={Transient chaos in bidirectional encoder representations from transformers},
   volume={4},
   ISSN={2643-1564},
   url={http://dx.doi.org/10.1103/PhysRevResearch.4.013204},
   DOI={10.1103/physrevresearch.4.013204},
   number={1},
   journal={Physical Review Research},
   publisher={American Physical Society (APS)},
   author={Inoue, Katsuma and Ohara, Soh and Kuniyoshi, Yasuo and Nakajima, Kohei},
   year={2022},
   month=mar }

@article{katharopoulos2020transformersrnnsfastautoregressive,
      title={Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention}, 
      author={Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and Fran√ßois Fleuret},
      year={2020},
      eprint={2006.16236},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.16236}, 
}