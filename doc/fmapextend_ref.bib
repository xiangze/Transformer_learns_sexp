@article{kobayashi2024analyzing,
title={Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps},
author={Goro Kobayashi and Tatsuki Kuribayashi and Sho Yokoi and Kentaro Inui},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=mYWsyTuiRp}
}

@article{PhysRevLett.94.058102,
  title = {Magic Number $7\ifmmode\pm\else\textpm\fi{}2$ in Networks of Threshold Dynamics},
  author = {Ishihara, Shuji and Kaneko, Kunihiko},
  journal = {Phys. Rev. Lett.},
  volume = {94},
  issue = {5},
  pages = {058102},
  numpages = {4},
  year = {2005},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.94.058102},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.94.058102}
}
@article{Inoue_2022,
   title={Transient chaos in bidirectional encoder representations from transformers},
   volume={4},
   ISSN={2643-1564},
   url={http://dx.doi.org/10.1103/PhysRevResearch.4.013204},
   DOI={10.1103/physrevresearch.4.013204},
   number={1},
   journal={Physical Review Research},
   publisher={American Physical Society (APS)},
   author={Inoue, Katsuma and Ohara, Soh and Kuniyoshi, Yasuo and Nakajima, Kohei},
   year={2022},
   month=mar }

@article{katharopoulos2020transformersrnnsfastautoregressive,
      title={Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention}, 
      author={Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and Fran√ßois Fleuret},
      year={2020},
      eprint={2006.16236},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.16236}, 
}

@inproceedings{clark2019what,
  title = {What Does BERT Look At? An Analysis of BERT's Attention},
  author = {Kevin Clark and Urvashi Khandelwal and Omer Levy and Christopher D. Manning},
  booktitle = {BlackBoxNLP@ACL},
  year = {2019}
}
@misc{funcvec
      title={Function Vectors in Large Language Models}, 
      author={Eric Todd and Millicent L. Li and Arnab Sen Sharma and Aaron Mueller and Byron C. Wallace and David Bau},
      year={2024},
      eprint={2310.15213},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15213}, 
}
@misc{olsson2022incontextlearninginductionheads,
      title={In-context Learning and Induction Heads}, 
      author={Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
      year={2022},
      eprint={2209.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.11895}, 
}